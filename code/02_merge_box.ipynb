{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "import calendar\n",
    "import geopandas as gpd\n",
    "import os.path as os\n",
    "import scipy.stats\n",
    "import seaborn.palettes\n",
    "import seaborn.utils\n",
    "import sys\n",
    "from census import Census\n",
    "from us import states\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "#import config\n",
    "import quickstart\n",
    "\n",
    "root= r\"C:/Users/Jennah/Desktop/Code/machine-learning-final\"\n",
    "inp= os.join(root, \"data\", \"2_intermediate\")\n",
    "out= os.join(root, \"data\", \"3_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth() # Creates local webserver and auto handles authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in clean data google drive\n",
    "from pydrive.drive import GoogleDrive\n",
    "drive = GoogleDrive(gauth)\n",
    "fileList = drive.ListFile({'q': \"'1jxSI_nq32-W9kPHKvQkzuNGJ5aIBD2j2' in parents and trashed=false\"}).GetList()\n",
    "for file in fileList:\n",
    "  print('Title: %s, ID: %s' % (file['title'], file['id']))\n",
    "  # Get the folder ID that you want\n",
    "  if(file['title'] == \"To Share\"):\n",
    "      fileID = file['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files in intermediate data\n",
    "from pydrive.drive import GoogleDrive\n",
    "drive = GoogleDrive(gauth)\n",
    "fileList = drive.ListFile({'q': \"'1kiYbPtSYavHQKzyMWtXaLhP-JM2toXRm' in parents and trashed=false\"}).GetList()\n",
    "for file in fileList:\n",
    "  print('Title: %s, ID: %s' % (file['title'], file['id']))\n",
    "  # Get the folder ID that you want\n",
    "  if(file['title'] == \"To Share\"):\n",
    "      fileID = file['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Fire Dispatch Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = drive.CreateFile({'id': '1zYSWlWtgNWsruaEkSSCqyXHIIdq7BEAP'})\n",
    "fires.GetContentFile('fire_dispatch.csv')  \n",
    "\n",
    "df_fires= pd.read_csv('fire_dispatch.csv').drop(\"Unnamed: 0\", axis = 1)\n",
    "df_fires.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load building level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csv = drive.CreateFile({'id': '1yYX-ROr1c7fzcQiG6NZ1sh7Ko5gqr_4G'})\n",
    "csv.GetContentFile('bld_predictors.csv')  \n",
    "\n",
    "df_bld= pd.read_csv('bld_predictors.csv').drop(\"Unnamed: 0\", axis = 1)\n",
    "df_bld.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing bbl values\n",
    "df_bld= df_bld.drop(df_bld[df_bld[\"bbl\"].isna()].index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load borobox/bbl crosswalk\n",
    "box = drive.CreateFile({'id': '1Yf4xIIOBmKU2WIlImat8qaN3z2L239Nw'})\n",
    "box.GetContentFile('pluto_box.csv')  \n",
    "\n",
    "df_box= pd.read_csv('pluto_box.csv').drop(\"Unnamed: 0\", axis = 1)\n",
    "df_box.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld_box= pd.merge(df_bld, df_box[[\"bbl\", \"borobox\", \"dist\"]], on = \"bbl\", indicator = True, how = \"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bld_box[\"_merge\"].value_counts()\n",
    "df_bld_box= df_bld_box.loc[df_bld_box[\"_merge\"] == \"both\", :]\n",
    "\n",
    "assert (df_bld_box[\"_merge\"] == \"both\").all()\n",
    "df_bld_box.drop(\"_merge\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landusecols = [\"landuse_\" + str(x) for x in df_bld[\"landuse\"].unique()]\n",
    "bldgclasscols = [\"bldgclass_\" + str(x) for x in df_bld[\"bldgclass\"].unique()]\n",
    "\n",
    "df_bld= pd.merge(df_bld, \\\n",
    "                      pd.get_dummies(df_bld[[\"bbl\", \"landuse\", \"bldgclass\"]], columns = [\"landuse\", \"bldgclass\"]), on = \"bbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load predictors and predictors for acs\n",
    "df_bld.columns\n",
    "predictors = [\"lotarea\", \"bldgarea\", \"numbldgs\", \"numfloors\", \"unitsres\", \"unitstotal\", \"assessland\",\n",
    "             \"assesstot\", \"exempttot\", \"yearbuilt\", \"holc_AB\", \"holc_CD\", \"holc_D\",\n",
    "             \"tot_hpd_vio\", \"hpd_fire_vio\", \"hpd_b_c_vio\",\n",
    "             \"viol_count_per_unit\", \"hpd_fire_vio_per_unit\", \"hpd_b_c_vio_per_unit\",\n",
    "             \"AL\", \"NB\", \"average_energy_usage\", \"average_energy_usage_mi\"]\n",
    "\n",
    "predictors_acs= df_bld.columns[df_bld.columns.get_loc(\"totpop\"):df_bld.columns.get_loc(\"crowdingrenter\") + 1].tolist()\n",
    "predictors_full= predictors + predictors_acs + landusecols + bldgclasscols\n",
    "predictors_full\n",
    "\n",
    "df_box_sum= df_bld_box.groupby(\"borobox\", as_index = False)[predictors].apply(lambda x: x.mean(skipna = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load weighted census data\n",
    "wgt_census = drive.CreateFile({'id': '1H8yM7UH14YdMqi5ASjHMd_dwA4C7-lKe'})\n",
    "wgt_census.GetContentFile('wgt_census.csv')  \n",
    "\n",
    "df_wgt_census= pd.read_csv('wgt_census.csv').drop([\"Unnamed: 0\", \"level_0\", \"index\"], axis = 1)\n",
    "df_wgt_census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_acs= pd.merge(df_box_sum, df_wgt_census, on = \"borobox\", indicator = True)\n",
    "assert all(df_box_acs[\"_merge\"] == \"both\")\n",
    "\n",
    "# drop merge var\n",
    "df_box_acs= df_box_acs.drop(\"_merge\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge to outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_final= pd.merge(df_box_acs, df_fires, on = \"borobox\", indicator = True, how = \"left\")\n",
    "df_box_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_box_final.shape)\n",
    "df_box_final[\"_merge\"].value_counts()\n",
    "\n",
    "assert (df_box_final[\"_merge\"] == \"both\").all()\n",
    "df_box_final.drop(\"_merge\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## investigate missing values\n",
    "df_box_final.loc[df_box_final[\"medianhhincome\"].isna(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate/fill missing values\n",
    "print(df_box_final.isna().sum(axis = 0).sort_values(ascending = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_final= df_box_final.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export analytic file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_final.to_csv(os.join(root, \"data\", \"3_clean\", \"analysis_box.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMorEa7Z8ODUCEPTOlT1br+",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "nyc fire risk",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
