{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a018be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "import requests\n",
    "import calendar\n",
    "import geopandas as gpd\n",
    "import os.path as os\n",
    "import scipy.stats\n",
    "import sys\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "import config\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "root= r\"C:/Users/Jennah/Desktop/Code/machine-learning-final\"\n",
    "inp= os.join(root, \"data\", \"3_clean\")\n",
    "interm= os.join(root, \"data\", \"2_intermediate\")\n",
    "\n",
    "plots= os.join(root, \"code\", \"plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5a1d533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your browser has been opened to visit:\n",
      "\n",
      "    https://accounts.google.com/o/oauth2/auth?client_id=570719947456-53haph7mjc317oel1ujh0kmjbfd499jf.apps.googleusercontent.com&redirect_uri=http%3A%2F%2Flocalhost%3A8080%2F&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&access_type=offline&response_type=code\n",
      "\n",
      "Authentication successful.\n"
     ]
    }
   ],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "\n",
    "gauth = GoogleAuth()\n",
    "gauth.LocalWebserverAuth() # Creates local webserver and auto handles authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c20fb011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: analysis_box.csv, ID: 1Vzjvta98IG9Hg4SfAGcd8JD8FaF3IXwy\n",
      "Title: analysis_bbl.csv, ID: 1yYX-ROr1c7fzcQiG6NZ1sh7Ko5gqr_4G\n",
      "Title: analysis_bbl_noacs.csv, ID: 1h-tDpBSslfzqzsJe1ny_ujDnr68RKry3\n",
      "Title: borobox_convex_hull.geojson, ID: 1SzBNj3Ba-v9MEwuCkZT9e9iAwVYUqx8r\n"
     ]
    }
   ],
   "source": [
    "# files in clean data google drive\n",
    "from pydrive.drive import GoogleDrive\n",
    "drive = GoogleDrive(gauth)\n",
    "fileList = drive.ListFile({'q': \"'1jxSI_nq32-W9kPHKvQkzuNGJ5aIBD2j2' in parents and trashed=false\"}).GetList()\n",
    "for file in fileList:\n",
    "  print('Title: %s, ID: %s' % (file['title'], file['id']))\n",
    "  # Get the folder ID that you want\n",
    "  if(file['title'] == \"To Share\"):\n",
    "      fileID = file['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc69dec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jennah\\anaconda3\\envs\\geo_env\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "      <th>Source</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Include_BBL</th>\n",
       "      <th>Include_Box</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>geofips</td>\n",
       "      <td>census tract geo identifier</td>\n",
       "      <td>Census ACS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>geofips_recode</td>\n",
       "      <td>census tract geo identifier, changes county to...</td>\n",
       "      <td>Census ACS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>totpop</td>\n",
       "      <td>total population</td>\n",
       "      <td>Census ACS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>popdens</td>\n",
       "      <td>total population per square mile</td>\n",
       "      <td>Census ACS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>areasqmile</td>\n",
       "      <td>area</td>\n",
       "      <td>Census ACS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Variable                                        Description  \\\n",
       "0         geofips                        census tract geo identifier   \n",
       "1  geofips_recode  census tract geo identifier, changes county to...   \n",
       "2          totpop                                   total population   \n",
       "3         popdens                   total population per square mile   \n",
       "4      areasqmile                                               area   \n",
       "\n",
       "       Source Notes  Include_BBL  Include_Box  \n",
       "0  Census ACS   NaN          0.0          0.0  \n",
       "1  Census ACS   NaN          0.0          0.0  \n",
       "2  Census ACS   NaN          1.0          1.0  \n",
       "3  Census ACS   NaN          1.0          1.0  \n",
       "4  Census ACS   NaN          1.0          1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load codebook        \n",
    "codebk = drive.CreateFile({'id': '1Lf7kV9_R-caFZV6_l8hMxAVjFSVFhvYl'})\n",
    "codebk.GetContentFile('codebook.xlsx')  \n",
    "\n",
    "codebk= pd.read_excel('codebook.xlsx', sheet_name = \"predictors\")\n",
    "codebk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd2b260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2            totpop\n",
       "3           popdens\n",
       "4        areasqmile\n",
       "5             males\n",
       "6           females\n",
       "           ...     \n",
       "164    bldgclass_A2\n",
       "165    bldgclass_A0\n",
       "166    bldgclass_A6\n",
       "167    bldgclass_A8\n",
       "168    bldgclass_CM\n",
       "Name: Variable, Length: 150, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_full = codebk.loc[codebk[\"Include_Box\"] == 1, \"Variable\"].apply(lambda x: x.strip())\n",
    "predictors_full"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ea72d",
   "metadata": {},
   "source": [
    "## Load analysis file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6d3b78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>borobox</th>\n",
       "      <th>lotarea</th>\n",
       "      <th>bldgarea</th>\n",
       "      <th>numbldgs</th>\n",
       "      <th>numfloors</th>\n",
       "      <th>unitsres</th>\n",
       "      <th>unitstotal</th>\n",
       "      <th>assessland</th>\n",
       "      <th>assesstot</th>\n",
       "      <th>exempttot</th>\n",
       "      <th>...</th>\n",
       "      <th>pctmvdsamecounty</th>\n",
       "      <th>pctmvdsdiffcounty</th>\n",
       "      <th>pctmvdsdiffstate</th>\n",
       "      <th>pctmvdabroad</th>\n",
       "      <th>pctpoprenterhh</th>\n",
       "      <th>engines_assigned_quantity</th>\n",
       "      <th>ladders_assigned_quantity</th>\n",
       "      <th>dispatch_response_seconds_qy</th>\n",
       "      <th>num_fire_ev</th>\n",
       "      <th>avg_fire_ev_yr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0020</td>\n",
       "      <td>3457.956522</td>\n",
       "      <td>9239.391304</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>3.521739</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.043478</td>\n",
       "      <td>3.718826e+04</td>\n",
       "      <td>8.482943e+05</td>\n",
       "      <td>2.937391e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279476</td>\n",
       "      <td>13.100437</td>\n",
       "      <td>3.580786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>32.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B0023</td>\n",
       "      <td>26081.875000</td>\n",
       "      <td>209572.375000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>229.750000</td>\n",
       "      <td>231.125000</td>\n",
       "      <td>1.322048e+06</td>\n",
       "      <td>1.219295e+07</td>\n",
       "      <td>2.589945e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279476</td>\n",
       "      <td>13.100437</td>\n",
       "      <td>3.580786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>42.333333</td>\n",
       "      <td>3</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B0024</td>\n",
       "      <td>2754.847826</td>\n",
       "      <td>4832.108696</td>\n",
       "      <td>1.086957</td>\n",
       "      <td>3.217391</td>\n",
       "      <td>5.695652</td>\n",
       "      <td>5.847826</td>\n",
       "      <td>4.959654e+04</td>\n",
       "      <td>5.346010e+05</td>\n",
       "      <td>4.643715e+04</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279476</td>\n",
       "      <td>13.100437</td>\n",
       "      <td>3.580786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>2.040000</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>25</td>\n",
       "      <td>1.923077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B0025</td>\n",
       "      <td>61653.000000</td>\n",
       "      <td>85292.250000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>10.750000</td>\n",
       "      <td>101.500000</td>\n",
       "      <td>102.000000</td>\n",
       "      <td>8.558175e+05</td>\n",
       "      <td>3.580575e+06</td>\n",
       "      <td>2.746800e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279476</td>\n",
       "      <td>13.100437</td>\n",
       "      <td>3.580786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>15.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>1.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B0027</td>\n",
       "      <td>3888.574713</td>\n",
       "      <td>8242.965517</td>\n",
       "      <td>1.126437</td>\n",
       "      <td>3.183908</td>\n",
       "      <td>7.080460</td>\n",
       "      <td>7.402299</td>\n",
       "      <td>4.881548e+04</td>\n",
       "      <td>6.619610e+05</td>\n",
       "      <td>1.669940e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279476</td>\n",
       "      <td>13.100437</td>\n",
       "      <td>3.580786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432729</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>2.340909</td>\n",
       "      <td>32.181818</td>\n",
       "      <td>44</td>\n",
       "      <td>2.933333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  borobox       lotarea       bldgarea  numbldgs  numfloors    unitsres  \\\n",
       "0   B0020   3457.956522    9239.391304  1.173913   3.521739    9.000000   \n",
       "1   B0023  26081.875000  209572.375000  1.000000  18.750000  229.750000   \n",
       "2   B0024   2754.847826    4832.108696  1.086957   3.217391    5.695652   \n",
       "3   B0025  61653.000000   85292.250000  1.250000  10.750000  101.500000   \n",
       "4   B0027   3888.574713    8242.965517  1.126437   3.183908    7.080460   \n",
       "\n",
       "   unitstotal    assessland     assesstot     exempttot  ...  \\\n",
       "0    9.043478  3.718826e+04  8.482943e+05  2.937391e+03  ...   \n",
       "1  231.125000  1.322048e+06  1.219295e+07  2.589945e+06  ...   \n",
       "2    5.847826  4.959654e+04  5.346010e+05  4.643715e+04  ...   \n",
       "3  102.000000  8.558175e+05  3.580575e+06  2.746800e+06  ...   \n",
       "4    7.402299  4.881548e+04  6.619610e+05  1.669940e+05  ...   \n",
       "\n",
       "   pctmvdsamecounty  pctmvdsdiffcounty  pctmvdsdiffstate  pctmvdabroad  \\\n",
       "0          4.279476          13.100437          3.580786           0.0   \n",
       "1          4.279476          13.100437          3.580786           0.0   \n",
       "2          4.279476          13.100437          3.580786           0.0   \n",
       "3          4.279476          13.100437          3.580786           0.0   \n",
       "4          4.279476          13.100437          3.580786           0.0   \n",
       "\n",
       "   pctpoprenterhh  engines_assigned_quantity  ladders_assigned_quantity  \\\n",
       "0        0.432729                   3.500000                   2.333333   \n",
       "1        0.432729                   3.000000                   2.000000   \n",
       "2        0.432729                   3.200000                   2.040000   \n",
       "3        0.432729                   2.400000                   1.600000   \n",
       "4        0.432729                   3.545455                   2.340909   \n",
       "\n",
       "   dispatch_response_seconds_qy  num_fire_ev  avg_fire_ev_yr  \n",
       "0                     32.666667            6        1.200000  \n",
       "1                     42.333333            3        3.000000  \n",
       "2                     36.880000           25        1.923077  \n",
       "3                     15.600000            5        1.666667  \n",
       "4                     32.181818           44        2.933333  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_box = drive.CreateFile({'id': '1Vzjvta98IG9Hg4SfAGcd8JD8FaF3IXwy'})\n",
    "df_box.GetContentFile('analysis_box.csv')  \n",
    "\n",
    "df_box= pd.read_csv('analysis_box.csv').drop([\"Unnamed: 0\"], axis = 1)\n",
    "df_box.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6298f8f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21716/951757585.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mdf_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mdf_box\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert df_box.dropna().shape[0] == df_box.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box.columns\n",
    "predictors = [\"lotarea\", \"bldgarea\", \"numbldgs\", \"numfloors\", \"unitsres\", \"unitstotal\", \"assessland\",\n",
    "             \"assesstot\", \"exempttot\", \"yearbuilt\", \"holc_AB\", \"holc_CD\", \"holc_D\",\n",
    "             \"tot_hpd_vio\", \"hpd_fire_vio\", \"hpd_b_c_vio\",\n",
    "             \"viol_count_per_unit\", \"hpd_fire_vio_per_unit\", \"hpd_b_c_vio_per_unit\",\n",
    "             \"AL\", \"NB\", \"average_energy_usage\", \"average_energy_usage_mi\"]\n",
    "\n",
    "predictors_acs= df_box.columns[df_box.columns.get_loc(\"totpop\"):df_box.columns.get_loc(\"pctrentocch\") + 1].tolist()\n",
    "landusecols= [x for x in df_box.columns if x in 'landuse_']\n",
    "bldgclasscols= [x for x in df_box.columns if x in 'bldgclass_']\n",
    "\n",
    "predictors_full= predictors + predictors_acs  + landusecols + bldgclasscols\n",
    "predictors_full;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa2271",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes= [\"dispatch_response_seconds_qy\", \"num_fire_ev\", \"avg_fire_ev_yr\"]\n",
    "df_box[outcomes].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18dfcca",
   "metadata": {},
   "source": [
    "# (0) Prep data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa38421a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_box.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fd7747",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box.loc[df_box[\"avg_fire_ev_yr\"]==0].shape[0]/df_box.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99d18d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert no missingness\n",
    "assert (df_box.isna().sum(axis = 0).sum() == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_box_clean= df_box.dropna(how = \"any\")\n",
    "df_box_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0eb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "X = df_box_clean.loc[:, predictors_full]\n",
    "y = df_box_clean.loc[X.index, outcomes]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c9c9de",
   "metadata": {},
   "source": [
    "### Running LASSO to determine important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53006d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "X_train_l, X_test_l, y_train_l, y_test_l = train_test_split(X_scaled, y, test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6608303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "coef_comp= pd.DataFrame(X.columns, columns = ['Features'])\n",
    "coef_comp\n",
    "\n",
    "param_grid= {'alpha':[.00001, 0.0001,0.001, 0.01, 0.5, 1, 1.5, 2]}\n",
    "clf= linear_model.Lasso(fit_intercept = True)\n",
    "gr = GridSearchCV(clf, param_grid=param_grid, n_jobs=-1)\n",
    "rs = gr.fit(X_train_l, y_train_l.iloc[:, 1])\n",
    "\n",
    "print(rs.best_params_)\n",
    "print(rs.best_score_)\n",
    "\n",
    "clf= linear_model.Lasso(fit_intercept = True, alpha = rs.best_params_['alpha'])\n",
    "clf.fit(X_train_l, y_train_l.iloc[:, 1])\n",
    "coef_comp['coef_alpha_0.5']= clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f3bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= linear_model.Lasso(fit_intercept = True, alpha = 3)\n",
    "clf.fit(X_train_l, y_train_l.iloc[:, 1])\n",
    "\n",
    "# feature selection from LASSOs\n",
    "# fewer features chosen\n",
    "coef_comp['coef_alpha_3']= clf.coef_\n",
    "lasso_coef= coef_comp.loc[coef_comp['coef_alpha_0.5'] != 0].sort_values('coef_alpha_0.5', ascending = False)\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e079ea3",
   "metadata": {},
   "source": [
    "# (1) Decision Trees and Random Forest Models\n",
    "* All are negative, suggests the model isn't performing very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60740f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "for c in range(3):\n",
    "    print(\"\\nDecision tree for\", outcomes[c])\n",
    "    print()\n",
    "    \n",
    "    dt1 = DecisionTreeRegressor(max_depth=10, random_state = 99)\n",
    "    dt1.fit(X_train, y_train.iloc[:, c])\n",
    "\n",
    "    dt2 = DecisionTreeRegressor(max_depth=15, random_state = 99)\n",
    "    dt2.fit(X_train, y_train.iloc[:, c])\n",
    "\n",
    "    y_pred1= dt1.predict(X_test)\n",
    "    y_pred2= dt2.predict(X_test)\n",
    "\n",
    "    print(\"R2 for model 1:\", dt1.score(X_test, y_test.iloc[:, c]))\n",
    "    print(\"R2 for model 2:\", dt2.score(X_test, y_test.iloc[:, c]))\n",
    "    \n",
    "    print(\"\\nMSE for model 1:\", mean_squared_error(y_test.iloc[:, c], y_pred1))\n",
    "    print(\"MSE for model 2:\", mean_squared_error(y_test.iloc[:, c], y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392fe285",
   "metadata": {},
   "source": [
    "## Tuning\n",
    "* There is a higher R2 for num_fire_ev and avg_fire_ev_yr\n",
    "* Seems to do well with a simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27412e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use max_depth to control the complexity of the tre\n",
    "param_grid = {'max_depth':np.arange(1, 20)}\n",
    "bp= []\n",
    "s= []\n",
    "for c in range(3):\n",
    "    dt=DecisionTreeRegressor()\n",
    "    gr=GridSearchCV(dt,param_grid=param_grid)\n",
    "    rs=gr.fit(X_train,y_train.iloc[:, c])\n",
    "    \n",
    "    bp+= [rs.best_params_]\n",
    "    s+= [rs.score(X_test, y_test.iloc[:, c])]\n",
    "    \n",
    "    print(\"\\nTuning decision tree for\", outcomes[c])\n",
    "    print(rs.best_params_)\n",
    "    print(rs.score(X_test, y_test.iloc[:, c]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80f3533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the R2 is pretty low...\n",
    "print(bp)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b301dc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## can we visualize the decision tree?\n",
    "## for num_fire_ev\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "dt = DecisionTreeRegressor(max_depth= 4, random_state = 99) #bp[1]['max_depth']) # since max depth is optimal for 3, use that\n",
    "dt.fit(X_train,y_train.iloc[:, 1])\n",
    "\n",
    "thestring = tree.export_graphviz(dt, out_file=None,  \n",
    "                         feature_names=X_train.columns.values, \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False).replace(\" ;\\n}\", \" ;}\")\n",
    "graph = pydotplus.graph_from_dot_data(thestring);\n",
    "graph.write_png(os.join(plots,'num_fire_ev_dt.png'))\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb2cab2",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ca2e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state = 99, max_depth= 2) #rs.best_params_['max_depth'])\n",
    "dt.fit(X_train, y_train)\n",
    "Feature_importance=pd.DataFrame([list(X_train.columns),list(dt.feature_importances_)]).T\n",
    "Feature_importance.columns=[\"variables\",\"importance\"]\n",
    "\n",
    "# list the top 10 most importnat features in order (using max_depth = 10)\n",
    "ft1= Feature_importance.sort_values(by=\"importance\",ascending=False).iloc[:10,:]\n",
    "ft1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f326119",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth=4, random_state = 99)\n",
    "dt.fit(X_train, y_train)\n",
    "Feature_importance=pd.DataFrame([list(X_train.columns),list(dt.feature_importances_)]).T\n",
    "Feature_importance.columns=[\"variables\",\"importance\"]\n",
    "\n",
    "# list the top 10 most important features in order (using max_Depth = 4)\n",
    "ft2= Feature_importance.sort_values(by=\"importance\",ascending=False).iloc[:10,:]\n",
    "ft2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66461ee4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5), dpi=80)\n",
    "plt.bar(ft2.sort_values(by=\"importance\",ascending=False).iloc[:,0],\n",
    "        ft2.sort_values(by=\"importance\",ascending=False).iloc[:,1])\n",
    "plt.title(\"Feature Importance\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce37a77",
   "metadata": {},
   "source": [
    "## Random Forests\n",
    "* Only outcome is number of num_fire_ev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators=30, n_jobs=-1, max_depth = 4, random_state = 99)\n",
    "rf.fit(X_train, y_train.iloc[:, 1])\n",
    "y_pred=rf.predict(X_test)\n",
    "print(\"R2 with random forest:\", rf.score(X_test, y_test.iloc[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9019c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':range(1,30)}\n",
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=30, random_state = 99)\n",
    "gs = GridSearchCV(rf,param_grid=param_grid)\n",
    "rs = gs.fit(X_train,y_train.iloc[:, 1])\n",
    "y_pred= rs.predict(X_test)\n",
    "\n",
    "print(rs.best_params_)\n",
    "print(\"R2 with best paramters:\", rs.score(X_test, y_test.iloc[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ae0d3",
   "metadata": {},
   "source": [
    "### CMM Method and Other Ensemble Methods\n",
    "* [From Domingos, 1998](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.40.2710&rep=rep1&type=pdf)\n",
    "* Not much of an increase in accuracy compared to decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe20440",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_jobs=-1, n_estimators=30, random_state = 99, max_depth = 6) #rs.best_params_['max_depth'])\n",
    "rf.fit(X_train,y_train.iloc[:, 1])\n",
    "\n",
    "# randomly generate a sample of xs\n",
    "X_rand= pd.DataFrame({x:X_train[x].sample(n = round(0.5*X_train.shape[0])).reset_index(drop = True) for x in X_train.columns})\n",
    "y_rand= rf.predict(X_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0424f8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the cmm training datasets\n",
    "X_train_cmm= pd.concat([X_rand, X_train], axis = 0, ignore_index = True)\n",
    "y_train_cmm= pd.concat([round(pd.DataFrame(y_rand)), y_train.iloc[:, 1]], axis = 0, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be377d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth':range(1,30)}\n",
    "dt=DecisionTreeRegressor()\n",
    "gr=GridSearchCV(dt,param_grid=param_grid)\n",
    "rs=gr.fit(X_train_cmm, y_train_cmm)\n",
    "\n",
    "print(rs.best_params_)\n",
    "print(rs.score(X_test, y_test.iloc[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3d11e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## prediction\n",
    "pred = rs.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e9934",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(max_depth= 3, random_state = 99) #rs.best_params_['max_depth']) # since max depth is optimal for 3, use that\n",
    "dt.fit(X_train_cmm, y_train_cmm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664e683b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature_importance=pd.DataFrame([list(X_train_cmm.columns),list(dt.feature_importances_)]).T\n",
    "Feature_importance.columns=[\"variables\",\"importance\"]\n",
    "\n",
    "# list the top 10 most importnat features in order (using max_depth = 10)\n",
    "ft3= Feature_importance.sort_values(by=\"importance\",ascending=False)\n",
    "ft3.loc[ft3['importance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7689633",
   "metadata": {},
   "outputs": [],
   "source": [
    "## we can plot this\n",
    "from sklearn import tree\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "thestring = tree.export_graphviz(dt, out_file=None,  \n",
    "                         feature_names=X_train.columns.values, \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True,impurity=False).replace(\" ;\\n}\", \" ;}\")\n",
    "graph = pydotplus.graph_from_dot_data(thestring);\n",
    "graph.write_png(os.join(plots,'num_fire_ev_cmm.png'))\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff4ac72",
   "metadata": {},
   "source": [
    "# (2) Bayes Nets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91434696",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import HillClimbSearch\n",
    "from pgmpy.estimators import K2Score, BicScore, BDeuScore\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import BayesianEstimator\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5b387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## need to discretize outcomes\n",
    "df_box_disc= df_box.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cc43c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discretize each variable to four equal-frequency bins (quartiles)\n",
    "for i in df_box_disc.columns[1:]:\n",
    "    if len(df_box_disc.loc[:, i].unique()) > 5:\n",
    "        plt.hist(df_box_disc.loc[:, i], bins = 100);\n",
    "        plt.title(\"Histogram for {}\".format(i))\n",
    "        print(plt.show())\n",
    "        df_box_disc.loc[:, i] = pd.qcut(df_box_disc.loc[:, i], q=4, labels=False, duplicates = 'drop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077036e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## important vars\n",
    "impt_vars= outcomes[0:2] + ft3.loc[ft3['importance']>0, \"variables\"].tolist()\n",
    "impt_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb919a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test train split for testing DAG\n",
    "train, test = train_test_split(df_box_disc.loc[:, impt_vars], test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2b2d19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use hill climb search with BIC score, as in hw\n",
    "hc = HillClimbSearch(train)\n",
    "best_model = hc.estimate(scoring_method=BicScore(train))\n",
    "print(\"\\nDAG model edges:\")\n",
    "print(best_model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fe552d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DAG model nodes:\")\n",
    "print(best_model.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c24d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the CPD for the model\n",
    "model = BayesianNetwork(best_model.edges())\n",
    "model.fit(train.loc[:, impt_vars], estimator=BayesianEstimator, prior_type='BDeu', equivalent_sample_size=10)\n",
    "for cpd in model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)\n",
    "for n in model.nodes():\n",
    "    print(model.local_independencies(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b53ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pylab as plt\n",
    "fig = plt.gcf()\n",
    "\n",
    "values = ['red' if n in ['num_fire_ev', 'dispatch_response_seconds_qy'] else 'lightblue' for n in model.nodes()]\n",
    "# use networkx to draw DAG\n",
    "nx.draw(model, node_color=values, with_labels=True, font_color='black', node_size=200,font_size=10)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "fig.savefig('dag_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733f1e53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test.loc[:, [n for n in model.nodes() if n not in ['num_fire_ev', 'dispatch_response_seconds_qy']]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f450cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in impt_vars[0:2]:\n",
    "    print(\"\\nOS accuracy for: {}\".format(i))\n",
    "    print((pred[i].reset_index(drop = True) == test[i].reset_index(drop = True)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction just for time to the fire\n",
    "pred = model.predict(test.loc[:, [n for n in model.nodes() if n not in ['dispatch_response_seconds_qy']]], stochastic = True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ef2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOS accuracy time to the fire, includes num_fire_ev as predictor\")\n",
    "print((pred['dispatch_response_seconds_qy'].reset_index(drop = True) == test['dispatch_response_seconds_qy'].reset_index(drop = True)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379fb65",
   "metadata": {},
   "source": [
    "### Re-run Bayes Net with Feature Selection from LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e22b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "impt_vars= outcomes[0:2] + lasso_coef.loc[lasso_coef[\"coef_alpha_3\"] != 0, \"Features\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23959f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test train split for testing DAG\n",
    "train, test = train_test_split(df_box_disc.loc[:, impt_vars], test_size=0.3, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef222691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use hill climb search with BIC score, as in hw\n",
    "hc = HillClimbSearch(train)\n",
    "best_model = hc.estimate(scoring_method=BicScore(train))\n",
    "print(\"\\nDAG model edges:\")\n",
    "print(best_model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e17a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DAG model nodes:\")\n",
    "print(best_model.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a72d427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the CPD for the model\n",
    "model = BayesianNetwork(best_model.edges())\n",
    "model.fit(train.loc[:, impt_vars], estimator=BayesianEstimator, prior_type='BDeu', equivalent_sample_size=10)\n",
    "for cpd in model.get_cpds():\n",
    "    print(\"CPD of {variable}:\".format(variable=cpd.variable))\n",
    "    print(cpd)\n",
    "for n in model.nodes():\n",
    "    print(model.local_independencies(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671682db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pylab as plt\n",
    "fig = plt.gcf()\n",
    "\n",
    "values = ['red' if n in ['num_fire_ev', 'dispatch_response_seconds_qy'] else 'lightblue' for n in model.nodes()]\n",
    "# use networkx to draw DAG\n",
    "nx.draw(model, node_color=values, with_labels=True, font_color='black', node_size=200,font_size=10)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "fig.savefig('dag_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00eed26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test.loc[:, [n for n in model.nodes() if n not in ['num_fire_ev', 'dispatch_response_seconds_qy']]])\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a022bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in impt_vars[0:2]:\n",
    "    print(\"\\nOS accuracy for: {}\".format(i))\n",
    "    print((pred[i].reset_index(drop = True) == test[i].reset_index(drop = True)).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb01da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction just for time to the fire\n",
    "pred = model.predict(test.loc[:, [n for n in model.nodes() if n not in ['dispatch_response_seconds_qy']]], stochastic = True)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4b202b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nOS accuracy time to the fire, includes num_fire_ev as predictor\")\n",
    "print((pred['dispatch_response_seconds_qy'].reset_index(drop = True) == test['dispatch_response_seconds_qy'].reset_index(drop = True)).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5900213",
   "metadata": {},
   "source": [
    "### PC Method for Causal Model calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b19f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import PC\n",
    "from pgmpy.estimators.CITests import chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc9d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "## important vars\n",
    "impt_vars= outcomes[0:2] + ft3.loc[ft3['importance']>0, \"variables\"].tolist()\n",
    "impt_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ccafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create test train split for testing DAG\n",
    "train, test = train_test_split(df_box_disc.loc[:, impt_vars], test_size=0.3, random_state=999)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45a6c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_est = PC(train)\n",
    "\n",
    "# Step 1: construct undirected skeleton\n",
    "skel, separating_sets = pc_est.build_skeleton(significance_level=0.01)\n",
    "print(\"Undirected edges: \", skel.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5837f81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: partially directed acyclic graph \n",
    "pdag = pc_est.skeleton_to_pdag(skel, separating_sets)\n",
    "print(\"PDAG edges:       \", pdag.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d2bf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "\n",
    "values = ['red' if n in ['num_fire_ev'] else 'lightblue' for n in pdag.nodes()]\n",
    "# use networkx to draw DAG\n",
    "nx.draw(pdag, node_color=values, with_labels=True, font_color='black', node_size=200,font_size=10)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "fig.savefig('pdag_box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0d086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pc_est.estimate()\n",
    "print(\"DAG edges:        \", model.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.gcf()\n",
    "\n",
    "values = ['red' if n in ['num_fire_ev'] else 'lightblue' for n in model.nodes()]\n",
    "# use networkx to draw DAG\n",
    "nx.draw(model, node_color=values, with_labels=True, font_color='black', node_size=200,font_size=10)\n",
    "\n",
    "plt.figure(figsize = (12,10))\n",
    "fig.savefig('model_pdag_est_box.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1251bcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "geo_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
